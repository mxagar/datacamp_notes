{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407c14ed-e721-42e0-90b6-e7d1ea3c5e6c",
   "metadata": {},
   "source": [
    "# 4. Machine Learning for IoT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead11710-ab87-4fb3-bbd9-763fb06df61b",
   "metadata": {},
   "source": [
    "See the IoT Data Analysis guide: [`IoT_Datacamp.md`](../IoT_Datacamp.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864296af-2b52-424d-a3b3-7fa9539afe82",
   "metadata": {},
   "source": [
    "## 4.1 Basic Model Training: Split, Scale, Train, Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757f864-d6bd-48c5-8d39-8d9a90b30a22",
   "metadata": {},
   "source": [
    "Supervised machine learning algorithms have independent variables `X` and target/dependent variable(s) `y`. We split the data in `train` and `test` subsets; the `test` subset cannot be seen by the model during training.\n",
    "\n",
    "In time series, we cannot randomly split the dataset; we take the last 20% as the test subset.\n",
    "\n",
    "```python\n",
    "environment.columns\n",
    "# ['precipitation', 'wind-gust-speed', 'humidity', 'radiation', 'sunshine', 'wind-direction', 'wind-speed', 'pressure', 'temperature', 'target']\n",
    "\n",
    "environment.shape # (2972, 10)\n",
    "\n",
    "# Define the split day\n",
    "# limit_day = environment.index[int(environment.shape[0]*0.8)].date()\n",
    "limit_day = \"2018-10-27\"\n",
    "\n",
    "# Split the data\n",
    "train_env = environment[:limit_day]\n",
    "test_env = environment[limit_day:]\n",
    "\n",
    "# Print start and end dates\n",
    "print(show_start_end(train_env))\n",
    "print(show_start_end(test_env))\n",
    "\n",
    "# Split the data into X and y\n",
    "X_train = train_env.drop(\"target\", axis=1)\n",
    "y_train = train_env[\"target\"]\n",
    "X_test = test_env.drop(\"target\", axis=1)\n",
    "y_test = test_env[\"target\"]\n",
    "\n",
    "# Scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_s = sc.transform(X_train)\n",
    "X_test_s = sc.transform(X_test)\n",
    "X_train_s = pd.DataFrame(X_train_s, \n",
    "                         columns=X_train.columns, \n",
    "                         index=X_train.index)\n",
    "X_test_s = pd.DataFrame(X_test_s, \n",
    "                        columns=X_test.columns, \n",
    "                        index=X_test.index)\n",
    "\n",
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train_s, y_train)\n",
    "\n",
    "# Predict classes\n",
    "print(logreg.predict(X_test_s))\n",
    "\n",
    "# Score the model\n",
    "print(logreg.score(X_train_s, y_train))\n",
    "print(logreg.score(X_test_s, y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc1e66-cf09-49a9-9aa8-ae5afc8cd7d4",
   "metadata": {},
   "source": [
    "## 4.2 Develop Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebb3e6-b85d-495d-9cc4-5c47d4ebc858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

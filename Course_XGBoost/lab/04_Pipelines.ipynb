{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f914918-d5e8-4be5-baa0-47a52e4c9c20",
   "metadata": {},
   "source": [
    "# 4. Using XGBoost in Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9fc7d9-28b2-41f5-ac11-61cd2d1e1a49",
   "metadata": {},
   "source": [
    "These are my personal notes of the Datacamp course [Extreme Gradient Boosting with XGBoost](https://app.datacamp.com/learn/courses/extreme-gradient-boosting-with-xgboost).\n",
    "\n",
    "The course has 4 main sections:\n",
    "\n",
    "1. Classification\n",
    "2. Regression\n",
    "3. Fine-tuning XGBoost\n",
    "4. **Using XGBoost in Pipelines**: the current notebook.\n",
    "\n",
    "XGBoost is an implementation of the [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) algorithm in C++ which has bindings to other languages, such as Python. It has the following properties:\n",
    "\n",
    "- Fast.\n",
    "- Best performance.\n",
    "- Parallelizable, on a computer and across the network. So it can work with huge datasets distributed on several nodes/GPUs.\n",
    "- We can use it for classification and regression.\n",
    "- The [Python API](https://xgboost.readthedocs.io/en/stable/python/python_api.html) is easy to use and has two major flavors or sub-APIs:\n",
    "  - The **Scikit-Learn API**: We instantiate `XGBRegressor()` or `XGBClassifier` and then we can `fit()` and `predict()`, using the typical Scikit-Learn parameters; we can even use those objects with other Scikit-Learn modules, such as `GridSearchCV`.\n",
    "  - The **Learning API**: The native XGBoost Python API requires to convert the dataframes into `DMatrix` objects first; then, we have powerful methods which allow for tuning many parameters: `xgb.cv()`, `xgb.train()`. The native/learning API is very easy to use. **Note: the parameter names are different compared to the Scikit-Learn API!**\n",
    "\n",
    "Classification is the original supervised learning problem addressed by XGBoost, although it can also handle regression problems.\n",
    "\n",
    "### Installation\n",
    "\n",
    "```python\n",
    "# PIP\n",
    "pip install xgboost\n",
    "\n",
    "# Conda: General\n",
    "conda install -c conda-forge py-xgboost\n",
    "\n",
    "# Conda: CPU only\n",
    "conda install -c conda-forge py-xgboost-cpu\n",
    "\n",
    "# Conda: Use NVIDIA GPU: Linux x86_64\n",
    "conda install -c conda-forge py-xgboost-gpu\n",
    "\n",
    "# For tree visualization\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [4.1 Example of Pipelines](#4.1-Example-of-Pipelines)\n",
    "- [4.2 Data Processing in Pipelines](#4.2-Data-Processing-in-Pipelines)\n",
    "    - Categoricals: LabelEncoder\n",
    "    - Categoricals: OneHotEncoder\n",
    "    - Pipeline\n",
    "    - Cross-Validation\n",
    "- [4.3 Full Pipeline Example: Kidney Disease Dataset](#4.3-Full-Pipeline-Example:-Kidney-Disease-Dataset)\n",
    "- [4.4 Housing Pipeline with Random Search Cross-Validation](#4.4-Housing-Pipeline-with-Random-Search-Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c888e-7c5c-4ac9-a8d2-47716e48678c",
   "metadata": {},
   "source": [
    "## 4.1 Example of Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ef2326-b931-4fd9-826d-2eb59ae9830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4febd820-3708-4d52-9698-c2bc874dd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ames_housing_trimmed_processed.csv\")\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5beff1bf-70b1-443f-ab6b-3b14c7ab6b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
       "0          0       1710             1             0  ...                  0   \n",
       "1          0       1262             0             1  ...                  0   \n",
       "2          1       1786             1             0  ...                  0   \n",
       "3          1       1717             1             0  ...                  0   \n",
       "4          0       2198             1             0  ...                  0   \n",
       "\n",
       "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
       "0                  0                0             0             1     208500  \n",
       "1                  0                0             0             1     181500  \n",
       "2                  0                0             0             1     223500  \n",
       "3                  0                0             0             1     140000  \n",
       "4                  0                0             0             1     250000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ef76f5-1354-4662-bb59-4a846b96abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([(\"st_scaler\", StandardScaler()),\n",
    "                        (\"rf_model\", RandomForestRegressor())])\n",
    "\n",
    "scores = cross_val_score(rf_pipeline,\n",
    "                         X,\n",
    "                         y,\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b56c1-220f-402f-8ac1-e931930d1a89",
   "metadata": {},
   "source": [
    "## 4.2 Data Processing in Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dea4be1-81d6-4de0-b8b5-50d79bfb202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ames_unprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c152c5-7e44-4cde-8af2-f7be931b09f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c49688f-c7ea-4d92-8702-00c972185313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass        0\n",
       "MSZoning          0\n",
       "LotFrontage     259\n",
       "LotArea           0\n",
       "Neighborhood      0\n",
       "BldgType          0\n",
       "HouseStyle        0\n",
       "OverallQual       0\n",
       "OverallCond       0\n",
       "YearBuilt         0\n",
       "Remodeled         0\n",
       "GrLivArea         0\n",
       "BsmtFullBath      0\n",
       "BsmtHalfBath      0\n",
       "FullBath          0\n",
       "HalfBath          0\n",
       "BedroomAbvGr      0\n",
       "Fireplaces        0\n",
       "GarageArea        0\n",
       "PavedDrive        0\n",
       "SalePrice         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a30997-d908-4fd6-9b41-e14f7b5ac647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   MSSubClass    1460 non-null   int64  \n",
      " 1   MSZoning      1460 non-null   object \n",
      " 2   LotFrontage   1201 non-null   float64\n",
      " 3   LotArea       1460 non-null   int64  \n",
      " 4   Neighborhood  1460 non-null   object \n",
      " 5   BldgType      1460 non-null   object \n",
      " 6   HouseStyle    1460 non-null   object \n",
      " 7   OverallQual   1460 non-null   int64  \n",
      " 8   OverallCond   1460 non-null   int64  \n",
      " 9   YearBuilt     1460 non-null   int64  \n",
      " 10  Remodeled     1460 non-null   int64  \n",
      " 11  GrLivArea     1460 non-null   int64  \n",
      " 12  BsmtFullBath  1460 non-null   int64  \n",
      " 13  BsmtHalfBath  1460 non-null   int64  \n",
      " 14  FullBath      1460 non-null   int64  \n",
      " 15  HalfBath      1460 non-null   int64  \n",
      " 16  BedroomAbvGr  1460 non-null   int64  \n",
      " 17  Fireplaces    1460 non-null   int64  \n",
      " 18  GarageArea    1460 non-null   int64  \n",
      " 19  PavedDrive    1460 non-null   object \n",
      " 20  SalePrice     1460 non-null   int64  \n",
      "dtypes: float64(1), int64(15), object(5)\n",
      "memory usage: 239.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ecd38-b8ac-4f04-baa8-848e0e5475cd",
   "metadata": {},
   "source": [
    "### Categoricals: LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4054fba-288e-4c1e-8e7c-8dfaf9eb392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSZoning Neighborhood BldgType HouseStyle PavedDrive\n",
      "0       RL      CollgCr     1Fam     2Story          Y\n",
      "1       RL      Veenker     1Fam     1Story          Y\n",
      "2       RL      CollgCr     1Fam     2Story          Y\n",
      "3       RL      Crawfor     1Fam     2Story          Y\n",
      "4       RL      NoRidge     1Fam     2Story          Y\n",
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == \"object\")\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13fd7f0-9314-47ae-b373-a8f7a2335fc1",
   "metadata": {},
   "source": [
    "### Categoricals: OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e8076f-6904-4f5c-8925-97f48dffdcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1460, 21)\n",
      "(1460, 3369)\n"
     ]
    }
   ],
   "source": [
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8e691-5a10-48b5-a9ca-def3406a6bf6",
   "metadata": {},
   "source": [
    "### Categoricals: DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5614f8b-8438-412e-bf6e-74214612104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 2.000e+00 5.480e+02\n",
      "  1.710e+03 1.000e+00 5.000e+00 8.450e+03 6.500e+01 6.000e+01 3.000e+00\n",
      "  5.000e+00 5.000e+00 7.000e+00 2.000e+00 0.000e+00 2.085e+05 2.003e+03]\n",
      " [3.000e+00 0.000e+00 0.000e+00 1.000e+00 1.000e+00 2.000e+00 4.600e+02\n",
      "  1.262e+03 0.000e+00 2.000e+00 9.600e+03 8.000e+01 2.000e+01 3.000e+00\n",
      "  2.400e+01 8.000e+00 6.000e+00 2.000e+00 0.000e+00 1.815e+05 1.976e+03]\n",
      " [3.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00 6.080e+02\n",
      "  1.786e+03 1.000e+00 5.000e+00 1.125e+04 6.800e+01 6.000e+01 3.000e+00\n",
      "  5.000e+00 5.000e+00 7.000e+00 2.000e+00 1.000e+00 2.235e+05 2.001e+03]\n",
      " [3.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 6.420e+02\n",
      "  1.717e+03 0.000e+00 5.000e+00 9.550e+03 6.000e+01 7.000e+01 3.000e+00\n",
      "  6.000e+00 5.000e+00 7.000e+00 2.000e+00 1.000e+00 1.400e+05 1.915e+03]\n",
      " [4.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00 8.360e+02\n",
      "  2.198e+03 1.000e+00 5.000e+00 1.426e+04 8.400e+01 6.000e+01 3.000e+00\n",
      "  1.500e+01 5.000e+00 8.000e+00 2.000e+00 0.000e+00 2.500e+05 2.000e+03]]\n",
      "{'MSSubClass': 12, 'MSZoning': 13, 'LotFrontage': 11, 'LotArea': 10, 'Neighborhood': 14, 'BldgType': 1, 'HouseStyle': 9, 'OverallQual': 16, 'OverallCond': 15, 'YearBuilt': 20, 'Remodeled': 18, 'GrLivArea': 7, 'BsmtFullBath': 2, 'BsmtHalfBath': 3, 'FullBath': 5, 'HalfBath': 8, 'BedroomAbvGr': 0, 'Fireplaces': 4, 'GarageArea': 6, 'PavedDrive': 17, 'SalePrice': 19}\n"
     ]
    }
   ],
   "source": [
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "# Each row becomes a dictionary with key = col name and value = cell value\n",
    "# All dictionaries/rows are inside a list\n",
    "df_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "# Print the resulting first five rows\n",
    "print(df_encoded[:5,:])\n",
    "\n",
    "# Print the vocabulary\n",
    "# NOTE: the order of the columns is not preserved!\n",
    "# The dv.vocabulary_ maps the column index of df_encoded to a column name\n",
    "# but the original order is not preserved.\n",
    "# Thus, the df_encoded matrix is compliant with dv.vocabulary_ but the column\n",
    "# order is new.\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52191612-97c8-4110-8b95-4fcbb9837ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 21)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5495f420-08bd-4b9f-a558-3a09f21e30e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddecb88f-f59e-428d-82e3-dbdbd7785b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MSSubClass': 60,\n",
       "  'MSZoning': 3,\n",
       "  'LotFrontage': 65.0,\n",
       "  'LotArea': 8450,\n",
       "  'Neighborhood': 5,\n",
       "  'BldgType': 0,\n",
       "  'HouseStyle': 5,\n",
       "  'OverallQual': 7,\n",
       "  'OverallCond': 5,\n",
       "  'YearBuilt': 2003,\n",
       "  'Remodeled': 0,\n",
       "  'GrLivArea': 1710,\n",
       "  'BsmtFullBath': 1,\n",
       "  'BsmtHalfBath': 0,\n",
       "  'FullBath': 2,\n",
       "  'HalfBath': 1,\n",
       "  'BedroomAbvGr': 3,\n",
       "  'Fireplaces': 0,\n",
       "  'GarageArea': 548,\n",
       "  'PavedDrive': 2,\n",
       "  'SalePrice': 208500},\n",
       " {'MSSubClass': 20,\n",
       "  'MSZoning': 3,\n",
       "  'LotFrontage': 80.0,\n",
       "  'LotArea': 9600,\n",
       "  'Neighborhood': 24,\n",
       "  'BldgType': 0,\n",
       "  'HouseStyle': 2,\n",
       "  'OverallQual': 6,\n",
       "  'OverallCond': 8,\n",
       "  'YearBuilt': 1976,\n",
       "  'Remodeled': 0,\n",
       "  'GrLivArea': 1262,\n",
       "  'BsmtFullBath': 0,\n",
       "  'BsmtHalfBath': 1,\n",
       "  'FullBath': 2,\n",
       "  'HalfBath': 0,\n",
       "  'BedroomAbvGr': 3,\n",
       "  'Fireplaces': 1,\n",
       "  'GarageArea': 460,\n",
       "  'PavedDrive': 2,\n",
       "  'SalePrice': 181500}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bc0e8-dbea-4b75-aab0-f382f2c0cb47",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f44f1-6dc9-427a-ac48-4fa3d3290504",
   "metadata": {},
   "source": [
    "Here, everything is done in a pipeline. Note that we need to use the Scikit-Learn API in order to pack the XGBoost models intoa pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c994807b-c42c-4fe8-a371-24137b888624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed6c741-17c5-43e4-9dfc-47e691be6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ames_housing_trimmed_processed.csv\")\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "000f9eb9-5833-4834-a46e-dee8c9f69124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ohe_onestep', DictVectorizer(sparse=False)),\n",
       "                ('xgb_model',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, enable_categorical=False,\n",
       "                              gamma=0, gpu_id=-1, importance_type=None,\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=6, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, subsample=1,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline\n",
    "xgb_pipeline.fit(X.to_dict(\"records\"), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126203a-2150-49b4-9a4b-199b38f01050",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f67106e7-39a2-4c1d-9508-aec254f283b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c96e0b6e-92c9-4449-aedb-dd645a9df0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ames_housing_trimmed_processed.csv\")\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2036957-1d68-4b55-8707-78da15741109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold RMSE:  27683.04157118635\n"
     ]
    }
   ],
   "source": [
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:squarederror\"))]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate the model\n",
    "cross_val_scores = cross_val_score(xgb_pipeline,\n",
    "                         X.to_dict(\"records\"),\n",
    "                         y,\n",
    "                         cv=10,\n",
    "                         scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Print the 10-fold RMSE\n",
    "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedca18-4990-4109-895e-c7877b8d1ed7",
   "metadata": {},
   "source": [
    "## 4.3 Full Pipeline Example: Kidney Disease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067f28e-a61f-4f2c-b298-eae8ba8587c1",
   "metadata": {},
   "source": [
    "We need to use the Scikit-Learn API in order to pack the XGBoost models intoa pipeline.\n",
    "\n",
    "In this section, the [chronic kidney disease dataset](https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease) is used, which requirems more data processing.\n",
    "\n",
    "From the dataset web:\n",
    "\n",
    "```\n",
    "1.Age(numerical) \n",
    "age in years \n",
    "2.Blood Pressure(numerical) \n",
    "bp in mm/Hg \n",
    "3.Specific Gravity(nominal) \n",
    "sg - (1.005,1.010,1.015,1.020,1.025) \n",
    "4.Albumin(nominal) \n",
    "al - (0,1,2,3,4,5) import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "5.Sugar(nominal) \n",
    "su - (0,1,2,3,4,5) \n",
    "6.Red Blood Cells(nominal) \n",
    "rbc - (normal,abnormal) \n",
    "7.Pus Cell (nominal) \n",
    "pc - (normal,abnormal) \n",
    "8.Pus Cell clumps(nominal) \n",
    "pcc - (present,notpresent) \n",
    "9.Bacteria(nominal) \n",
    "ba - (present,notpresent) \n",
    "10.Blood Glucose Random(numerical) \n",
    "bgr in mgs/dl \n",
    "11.Blood Urea(numerical) \n",
    "bu in mgs/dl \n",
    "12.Serum Creatinine(numerical) \n",
    "sc in mgs/dl \n",
    "13.Sodium(numerical) \n",
    "sod in mEq/L \n",
    "14.Potassium(numerical) \n",
    "pot in mEq/L \n",
    "15.Hemoglobin(numerical) \n",
    "hemo in gms \n",
    "16.Packed Cell Volume(numerical) \n",
    "17.White Blood Cell Count(numerical) \n",
    "wc in cells/cumm \n",
    "18.Red Blood Cell Count(numerical) \n",
    "rc in millions/cmm \n",
    "19.Hypertension(nominal) \n",
    "htn - (yes,no) \n",
    "20.Diabetes Mellitus(nominal) \n",
    "dm - (yes,no) \n",
    "21.Coronary Artery Disease(nominal) \n",
    "cad - (yes,no) \n",
    "22.Appetite(nominal) \n",
    "appet - (good,poor) \n",
    "23.Pedal Edema(nominal) \n",
    "pe - (yes,no) \n",
    "24.Anemia(nominal) \n",
    "ane - (yes,no) \n",
    "25.Class (nominal) \n",
    "class - (ckd,notckd)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3db64c5a-597d-4f11-839e-133d0a987b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "#from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bf19903c-ccb2-4e96-b17f-5cfcdbd82b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5eb2b8d6-ec9c-4c5d-837e-53c74de0f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "64c6c6f0-e594-4806-a30f-1adca5bf641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CSV has no column names, but I got them from the web/Datacamp\n",
    "# Also, note that NaN values are marked with a ?\n",
    "df = pd.read_csv(\"../data/chronic_kidney_disease.csv\", names=column_names, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9025b8cf-7f26-40da-9f2e-53b672f67fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     bgr        bu          sc         sod  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     pot  ...    pc     pcc   ba  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0  5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0  NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0  NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0  3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0  4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6650b3e2-e8c0-423c-893e-afdc8004057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 25)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e7a87670-f40b-4beb-8472-e3b10dd4b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     391 non-null    float64\n",
      " 1   bp      388 non-null    float64\n",
      " 2   sg      353 non-null    float64\n",
      " 3   al      354 non-null    float64\n",
      " 4   su      351 non-null    float64\n",
      " 5   bgr     248 non-null    object \n",
      " 6   bu      335 non-null    object \n",
      " 7   sc      396 non-null    object \n",
      " 8   sod     396 non-null    object \n",
      " 9   pot     356 non-null    float64\n",
      " 10  hemo    381 non-null    float64\n",
      " 11  pcv     383 non-null    float64\n",
      " 12  wc      313 non-null    float64\n",
      " 13  rc      312 non-null    float64\n",
      " 14  rbc     348 non-null    float64\n",
      " 15  pc      329 non-null    float64\n",
      " 16  pcc     294 non-null    float64\n",
      " 17  ba      269 non-null    float64\n",
      " 18  htn     398 non-null    object \n",
      " 19  dm      398 non-null    object \n",
      " 20  cad     398 non-null    object \n",
      " 21  appet   399 non-null    object \n",
      " 22  pe      399 non-null    object \n",
      " 23  ane     399 non-null    object \n",
      " 24  class   400 non-null    object \n",
      "dtypes: float64(14), object(11)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e01e14be-8acd-4186-939f-b55b3d1fce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d40d031c-5230-40d4-a806-f3ccaf446b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ckd', 'notckd'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c4e12e6a-334f-4d23-911f-256b9a39a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age        9\n",
      "bp        12\n",
      "sg        47\n",
      "al        46\n",
      "su        49\n",
      "bgr      152\n",
      "bu        65\n",
      "sc         4\n",
      "sod        4\n",
      "pot       44\n",
      "hemo      19\n",
      "pcv       17\n",
      "wc        87\n",
      "rc        88\n",
      "rbc       52\n",
      "pc        71\n",
      "pcc      106\n",
      "ba       131\n",
      "htn        2\n",
      "dm         2\n",
      "cad        2\n",
      "appet      1\n",
      "pe         1\n",
      "ane        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check number of nulls in each feature column\n",
    "nulls_per_column = X.isnull().sum()\n",
    "print(nulls_per_column)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_feature_mask = X.dtypes == object\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "# Get list of non-categorical column names\n",
    "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
    "\n",
    "# Apply numeric imputer\n",
    "numeric_imputation_mapper = DataFrameMapper(\n",
    "                                            [([numeric_feature], SimpleImputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
    "                                            input_df=True,\n",
    "                                            df_out=True\n",
    "                                           )\n",
    "\n",
    "# Apply categorical imputer\n",
    "categorical_imputation_mapper = DataFrameMapper(\n",
    "                                                [([category_feature], SimpleImputer(strategy=\"most_frequent\")) for category_feature in categorical_columns],\n",
    "                                                input_df=True,\n",
    "                                                df_out=True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6487cece-027d-4f1f-8dac-0d56dbc3c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer which converts a dataframe into a dictionary\n",
    "class Dictifier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Convert dataset to a dictionary.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "        return df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c5235113-7ea2-4b69-bb59-06f2f37da8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the numeric and categorical transformations\n",
    "numeric_categorical_union = FeatureUnion([\n",
    "                                          (\"num_mapper\", numeric_imputation_mapper),\n",
    "                                          (\"cat_mapper\", categorical_imputation_mapper)\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4bc23d2d-55cf-49d7-b424-d222b3ea7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full pipeline\n",
    "pipeline = Pipeline([\n",
    "                     (\"featureunion\", numeric_categorical_union),\n",
    "                     (\"dictifier\", Dictifier()),\n",
    "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
    "                     (\"clf\", xgb.XGBClassifier(max_depth=3, objective=\"binary:logistic\", use_label_encoder=False))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "03fee899-c52b-4731-a388-df2a6b6a124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4fe17f49-d9a3-42a3-8de1-8bba256556a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(pipeline,\n",
    "                         X,\n",
    "                         y,\n",
    "                         scoring=\"roc_auc\",\n",
    "                         cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ea6f05ec-69be-4370-a873-09c713977407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.   , 1.   , 1.   , 1.   , 0.992, 1.   , 1.   , 1.   , 1.   ,\n",
       "       1.   ])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290845a3-1dcf-417c-b8ce-93f029482172",
   "metadata": {},
   "source": [
    "## 4.4 Housing Pipeline with Random Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e549996b-fff8-40ed-bbda-41f1636c7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "data = pd.read_csv(\"../data/ames_housing_trimmed_processed.csv\")\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "984996ae-c79e-40be-bd17-2f621e6b28f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 57)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "68ded49f-ebec-4ffb-a113-021494176872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 56)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "479b4b63-6c0c-40e6-981b-645531bf7da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "55955524-456c-4ed2-9681-182912797a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
       "0          0       1710             1             0  ...                  0   \n",
       "1          0       1262             0             1  ...                  0   \n",
       "2          1       1786             1             0  ...                  0   \n",
       "3          1       1717             1             0  ...                  0   \n",
       "4          0       2198             1             0  ...                  0   \n",
       "\n",
       "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
       "0                  0                0             0             1     208500  \n",
       "1                  0                0             0             1     181500  \n",
       "2                  0                0             0             1     223500  \n",
       "3                  0                0             0             1     140000  \n",
       "4                  0                0             0             1     250000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ef27c384-842f-468b-9bfe-01d0238b6b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[('st_scaler', StandardScaler()),\n",
       "                                             ('xgb_model',\n",
       "                                              XGBRegressor(base_score=None,\n",
       "                                                           booster=None,\n",
       "                                                           colsample_bylevel=None,\n",
       "                                                           colsample_bynode=None,\n",
       "                                                           colsample_bytree=None,\n",
       "                                                           enable_categorical=False,\n",
       "                                                           gamma=None,\n",
       "                                                           gpu_id=None,\n",
       "                                                           importance_type=None,\n",
       "                                                           interaction_constraints=None,\n",
       "                                                           learning_rate=None,\n",
       "                                                           max_delta_step=None,\n",
       "                                                           max_depth=...\n",
       "                   param_distributions={'xgb_model__colsample_bytree': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
       "       0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
       "                                        'xgb_model__max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
       "                                        'xgb_model__subsample': array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipeline = Pipeline([(\"st_scaler\", StandardScaler()),\n",
    "                         (\"xgb_model\", xgb.XGBRegressor())])\n",
    "gbm_param_grid = {\n",
    "    'xgb_model__subsample': np.arange(.05, 1, .05),\n",
    "    'xgb_model__max_depth': np.arange(3,20,1),\n",
    "    'xgb_model__colsample_bytree': np.arange(.1,1.05,.05) }\n",
    "\n",
    "randomized_neg_mse = RandomizedSearchCV(estimator=xgb_pipeline,\n",
    "                                        param_distributions=gbm_param_grid, \n",
    "                                        n_iter=10,\n",
    "                                        scoring='neg_mean_squared_error', cv=4)\n",
    "\n",
    "randomized_neg_mse.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a9a67226-df2a-460f-bf19-df5bfb3cb4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rmse:  29969.312787260624\n"
     ]
    }
   ],
   "source": [
    "print(\"Best rmse: \", np.sqrt(np.abs(randomized_neg_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1e8bbbe3-24d2-4172-b513-d8581b71f2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  Pipeline(steps=[('st_scaler', StandardScaler()),\n",
      "                ('xgb_model',\n",
      "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "                              colsample_bylevel=1, colsample_bynode=1,\n",
      "                              colsample_bytree=0.25000000000000006,\n",
      "                              enable_categorical=False, gamma=0, gpu_id=-1,\n",
      "                              importance_type=None, interaction_constraints='',\n",
      "                              learning_rate=0.300000012, max_delta_step=0,\n",
      "                              max_depth=3, min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=100,\n",
      "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=0.8500000000000001,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \", randomized_neg_mse.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024a979-60fc-4c7a-8bfc-de6b84096cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
